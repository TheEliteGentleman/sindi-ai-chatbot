# Microprofile server properties
server.port=9080

dev.langchain4j.plugin.chat-model.class=dev.langchain4j.model.googleai.GoogleAiGeminiChatModel
#dev.langchain4j.plugin.chat-model.scope=jakarta.enterprise.context.ApplicationScoped
dev.langchain4j.plugin.chat-model.config.api-key=<ENTER YOUR OWN GEMINI KEY HERE OR INJECT IT SECURELY>
dev.langchain4j.plugin.chat-model.config.model-name=gemini-2.5-pro
dev.langchain4j.plugin.chat-model.config.temperature=0.1
dev.langchain4j.plugin.chat-model.config.topP=0.1
dev.langchain4j.plugin.chat-model.config.timeout=120s
dev.langchain4j.plugin.chat-model.config.max-retries=2
dev.langchain4j.plugin.chat-model.config.log-requests-and-responses=true
dev.langchain4j.plugin.chat-model.config.listeners=@all
dev.langchain4j.plugin.chat-model.config.supported-capabilities=dev.langchain4j.model.chat.Capability.RESPONSE_FORMAT_JSON_SCHEMA

dev.langchain4j.plugin.docRagRetriever.class=dev.langchain4j.rag.content.retriever.EmbeddingStoreContentRetriever
#dev.langchain4j.plugin.docRagRetriever.scope=jakarta.enterprise.context.ApplicationScoped
dev.langchain4j.plugin.docRagRetriever.config.embeddingStore=lookup:default
dev.langchain4j.plugin.docRagRetriever.config.embeddingModel=lookup:default
dev.langchain4j.plugin.docRagRetriever.config.maxResults=3
dev.langchain4j.plugin.docRagRetriever.config.minScore=0.6

# Chat Memory used by ChatAiService class
dev.langchain4j.plugin.chat-ai-service-memory.class=dev.langchain4j.memory.chat.MessageWindowChatMemory
dev.langchain4j.plugin.chat-ai-service-memory.scope=jakarta.enterprise.context.ApplicationScoped
dev.langchain4j.plugin.chat-ai-service-memory.config.maxMessages=10
